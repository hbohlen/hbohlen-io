# NixOS Configuration Architecture Document

### 1. Introduction

This document outlines the holistic architecture for the NixOS Configuration project. It establishes the foundational principles of **modularity, reusability, and a strict separation of concerns** that will govern the declarative system. The primary goal is to create a robust, scalable blueprint that not only ensures consistency across all target machines but is also explicitly designed for safe and effective modification by AI agents.

#### Starter Template or Existing Project
The project will be built from scratch. This "first-principles" approach was chosen to enforce a clean, unopinionated structure tailored precisely to the project's goals, avoiding the potential complexity or cruft from external templates. This ensures the resulting architecture is both minimal and highly intentional.

#### Change Log
| Date | Version | Description | Author |
| :--- | :--- | :--- | :--- |
| 2025-09-15 | 1.0 | Initial architecture draft | Winston (Architect) |

---
### 2. High Level Architecture

#### Technical Summary
The system's architecture is a declarative monorepo built on the NixOS ecosystem, utilizing Flakes for hermetic dependency management. It is composed of modular components, including distinct host-specific profiles (laptop, desktop, servers), reusable shared modules for common software, and user-level configurations managed by `home-manager`. Key architectural patterns include a strict separation of hardware-specific concerns from general software configuration, declarative disk management via `disko`, and secure secret handling with `sops-nix`. This approach directly supports the PRD's primary goals of achieving a reproducible, consistent, and rapidly provisioned environment across multiple machines.

#### High Level Overview
* **Architectural Style**: The system employs a **Declarative Configuration** model, where the desired state of each machine is explicitly defined in code, and the Nix tooling is responsible for realizing that state.
* **Repository Structure**: As specified in the PRD, the project will use a **Monorepo** structure to house all configurations for all target machines in a single version-controlled repository.
* **Primary Data Flow**: The primary flow begins with the root `flake.nix`, which imports host-specific configurations. Each host configuration then composes shared modules and its own unique hardware settings to produce a final, bootable system derivation.
* **Key Architectural Decisions**:
    * **Nix Flakes**: Chosen for providing hermetic, reproducible builds and managing all dependencies.
    * **`disko` for Disk Management**: Enables fully declarative and automated partitioning.
    * **`home-manager` Integration**: Ensures the entire user environment is reproducible.

#### High Level Project Diagram
```mermaid
graph TD
    subgraph "GitHub Monorepo"
        A[flake.nix] --> B{Host Profiles}
        A --> C(Shared Modules)
        A --> D(User Configs)
    end

    B --> B1[Laptop]
    B --> B2[Desktop]
    B --> B3[Server]

    C --> B1
    C --> B2
    C --> B3

    D -- home-manager --> B1
    D -- home-manager --> B2
    D -- home-manager --> B3

    subgraph "Hardware-Specific Modules"
        H1(Laptop Hardware)
        H2(Desktop Hardware)
    end

    H1 --> B1
    H2 --> B2

    subgraph "External Tools"
        T1[disko]
        T2[sops-nix]
    end

    T1 --> B1
    T1 --> B2
    T2 --> B3
```

#### Architectural and Design Patterns
* **Modular Configuration**: System definitions are broken into small, reusable Nix modules that can be composed to build a complete system.
* **Separation of Concerns (Hardware vs. Software)**: Host configurations are explicitly divided between modules that define the software environment and modules that define hardware-specific needs.
* **Declarative State Management**: Every aspect of the system is defined declaratively in Nix files.

#### Known Risks and Mitigation Strategies
* **Complexity Creep**: The "from scratch" approach requires discipline to prevent creating an overly complex web of custom modules. **Mitigation**: Adherence to the defined component structure and coding standards is critical.
* **Secret Management Brittleness**: `sops-nix` introduces a dependency on key management. **Mitigation**: The process for onboarding new machines and users to the secret management system must be thoroughly documented in the `README.md`.
* **Hardware-Specific Divergence**: Solutions for specific hardware (like the ASUS laptop) may require complex overrides. **Mitigation**: Keep hardware modules as isolated as possible and favor configuration flags over complex conditional logic in shared modules.
* **Flake Update Burden**: Updating flake inputs like `nixpkgs` can cause a cascade of build failures. **Mitigation**: Updates should be done on a separate branch and thoroughly tested via the VM strategy before being merged.

#### Analysis of Diagram Flow and Dependencies
The logical flow is one of **composition and specialization**. We start with a single root (`flake.nix`), define shared building blocks (`Shared Modules`, `User Configs`), and then compose them into specific `Host Profiles`, layering on hardware details and specialized tools only where required. This flow ensures maximum reusability and a clear dependency chain.

---
### 3. Tech Stack

#### Cloud Infrastructure
* **Provider**: Provider Agnostic (Initial targets: Hetzner, DigitalOcean)
* **Key Services**: Generic Compute (Linux VPS), Block Storage, DNS
* **Deployment Regions**: User-defined at deployment time (e.g., `us-east`, `fsn1-dc14`)

#### Technology Stack Table
| Category | Technology | Version | Purpose | Rationale |
| :--- | :--- | :--- | :--- | :--- |
| OS / Language | NixOS / Nix | `nixpkgs-24.05` | Declarative OS & package management | Core of the project for reproducibility. |
| Config Mgmt | Nix Flakes | Stable | Hermetic builds & dependency mgmt | Provides true reproducibility and version pinning. |
| User Env Mgmt | Home Manager | `0.40.0` | Declarative user dotfiles/packages | Ensures user environment is consistent across hosts. |
| Disk Mgmt | `disko` | `0.4.0` | Declarative disk partitioning | Automates and reproduces disk layouts. |
| Secrets Mgmt | `sops-nix` | `0.5.0` | Build-time secret decryption | Securely integrates secrets into the declarative build. |
| Interactive Secrets| 1Password CLI | `2.26.1` | Interactive user secret access | Provides convenient access to personal vaults for non-system tasks. |
| Version Control | Git | `2.45.1` | Source code management | Standard for version control. |
| CI/CD | GitHub Actions| N/A | Automated testing and checks | Specified in PRD Epic 4 for future automation. |
| VM Testing | NixOS VM Tests| N/A | Pre-deployment validation | Built-in NixOS feature for robust, automated testing. |

---
### 4. Data Models

#### Host
* **Purpose**: Represents a single, complete, and buildable machine configuration.
* **Attributes**: `name`, `system`, `modules`, `users`, `diskConfig`.
* **Relationships**: A Host is composed of Modules, has Users, and may use Secrets and a Hardware-Specific Module.

#### User
* **Purpose**: Represents a user account and their environment managed by Home Manager.
* **Attributes**: `username`, `homeDirectory`, `shell`, `packages`, `dotfiles`.
* **Relationships**: A User belongs to one or more Hosts and has one Home Manager Configuration.

#### Module
* **Purpose**: Represents a self-contained and reusable unit of configuration.
* **Attributes**: `name`, `type` ('Shared' or 'Hardware-Specific'), `path`, `configuration`.
* **Relationships**: A Module can be imported by Hosts and can be composed of other Modules.

---
### 5. Components

#### Hosts Component
* **Responsibility**: Contains the top-level, final configurations for each target machine.
* **Interfaces**: Exposes a `nixosConfigurations.<hostname>` output in the root `flake.nix`.

#### Modules Component
* **Responsibility**: The core library containing all reusable and specialized units of configuration.
* **Sub-Components**: Organized into `hardware/`, `programs/`, `services/`, and `profiles/`.

#### Users Component
* **Responsibility**: Contains all user-specific configurations, managed by Home Manager.

#### Secrets Component
* **Responsibility**: Manages all encrypted sensitive data for the system using `sops-nix`.

#### Scripts Component
* **Responsibility**: Contains operational and automation scripts like `install.sh`.

#### Component Diagram
```mermaid
graph TD
    subgraph "NixOS Monorepo"
        A[flake.nix]

        subgraph hosts
            direction LR
            H1[laptop]
            H2[desktop]
            H3[server]
        end

        subgraph modules
            direction LR
            M1[hardware/]
            M2[programs/]
            M3[services/]
            M4[profiles/]
        end

        subgraph users
            direction LR
            U1[hbohlen/]
        end

        subgraph secrets
            S1[secrets.yaml.sops]
        end

        subgraph scripts
            SC1[install.sh]
        end

        A -- orchestrates --> hosts
        A -- orchestrates --> modules
        A -- orchestrates --> users

        hosts -- imports from --> modules
        hosts -- imports from --> users
        H3 -- needs --> secrets

        scripts -- operates on --> A
    end
```

---
### 6. Core Workflows

#### Workflow 1: New Machine Installation
```mermaid
sequenceDiagram
    actor Administrator
    participant InstallScript as "scripts/install.sh"
    participant LiveISO as "Target Machine (Live ISO)"
    participant GitHub

    Administrator->>LiveISO: Boot into NixOS Installer
    Administrator->>LiveISO: Run `nix-shell -p git`
    LiveISO-->>Administrator: Provides temporary shell with git
    Administrator->>LiveISO: git clone <repo_url>
    Administrator->>InstallScript: Execute ./install.sh --flake .#<hostname>

    InstallScript->>GitHub: Fetch flake sources
    InstallScript->>LiveISO: Run Pre-flight Checks (VMD, Disks)
    alt Checks Pass
        InstallScript->>LiveISO: Run disko to partition disks
        InstallScript->>LiveISO: Run nixos-install for the flake target
        InstallScript->>LiveISO: Run Post-flight Validation
        InstallScript-->>Administrator: Log Success and prompt for reboot
    else Checks Fail
        InstallScript-->>Administrator: Log detailed error and exit
    end
```

#### Workflow 2: System Update and Rollback
```mermaid
sequenceDiagram
    actor Administrator
    participant LocalRepo as "Local Git Repo"
    participant GitHub
    participant TargetHost as "Target Host (e.g., Laptop)"

    Administrator->>LocalRepo: Edit Nix configuration
    Administrator->>LocalRepo: git commit & git push
    LocalRepo->>GitHub: Pushes changes

    Administrator->>TargetHost: SSH into machine

    par Update and Rollback
        section Update Process
            TargetHost->>GitHub: git pull
            Administrator->>TargetHost: sudo nixos-rebuild switch
            TargetHost-->>Administrator: Activates new configuration
        end

        section Rollback Process
            Administrator->>TargetHost: sudo nixos-rebuild switch --rollback
            TargetHost-->>Administrator: Immediately activates previous configuration
        end
    end
```

#### Workflow 3: Updating a Shared Module
```mermaid
sequenceDiagram
    actor Administrator
    participant LocalRepo as "Local Git Repo"
    participant GitHub
    participant Laptop
    participant Desktop

    Administrator->>LocalRepo: Edit a SHARED module (e.g., programs/development.nix)
    Administrator->>LocalRepo: git commit & git push
    LocalRepo->>GitHub: Pushes change to central repo

    Note over Laptop,Desktop: At different times, on each machine...

    Administrator->>Laptop: git pull && sudo nixos-rebuild switch
    Laptop->>GitHub: Pulls latest config
    Laptop-->>Administrator: Builds with updated shared module

    Administrator->>Desktop: git pull && sudo nixos-rebuild switch
    Desktop->>GitHub: Pulls latest config
    Desktop-->>Administrator: Builds with SAME updated shared module
```

---
### 7. Source Tree

```plaintext
hbohlen-io/
├── nixos/
│   ├── flake.nix
│   ├── flake.lock
│   ├── README.md
│   ├── .gitignore
│   ├── secrets/
│   │   └── secrets.yaml.sops
│   ├── scripts/
│   │   └── install.sh
│   ├── hosts/
│   │   ├── laptop/
│   │   │   ├── configuration.nix
│   │   │   └── disko.nix
│   │   └── ... (desktop, server)
│   ├── modules/
│   │   ├── hardware/
│   │   ├── programs/
│   │   ├── services/
│   │   └── profiles/
│   └── users/
│       └── hbohlen/
│           ├── home.nix
│           └── dotfiles/
├── apps/
│   └── (Future projects and services will live here)
└── packages/
    └── (Future shared libraries will live here)
```

---
### 8. Infrastructure and Deployment
The primary Infrastructure as Code (IaC) is the Nix configuration itself. Deployment is handled via a Git-based promotion flow, where changes are merged to `main`, pulled on the target host, and activated with `nixos-rebuild switch`. Rollbacks are handled by NixOS's built-in generation management.

---
### 9. Error Handling Strategy
The strategy relies on **Build-Time Validation** via the Nix evaluator, **Structured Logging** via `systemd-journald`, and the built-in **Rollback Strategy** for deployment failures. Long-term, this will be supplemented by a centralized observability platform like Datadog.

---
### 10. Coding Standards
All Nix code must be formatted with `nixpkgs-fmt`. The standards enforce strict separation of concerns (e.g., no hardware paths in shared modules) and the use of Nix's module system for configuration.

---
### 11. Test Strategy and Standards
The strategy is **VM-First Validation**. No change is deployed until it successfully builds and boots in a QEMU VM using NixOS's built-in testing framework. This will be automated via GitHub Actions in the future.

---
### 12. Security
The security posture relies on declarative management of user privileges, SSH public-key authentication for servers, full-disk encryption (LUKS) for physical machines, and encrypted secret management via `sops-nix`.

---
### 13. Next Steps
This architecture document is now complete. The next logical step is a final review by the Product Owner (`po`) to ensure alignment with the product vision. Once approved, the Scrum Master (`sm`) can begin the development phase by creating the first story (Story 1.1) from the PRD, using this architecture as the definitive technical guide.

---
### Checklist Results Report

#### Executive Summary
* **Project Type**: Backend / System Configuration (No UI)
* **Overall Architecture Readiness**: **High**
* **Critical Risks Identified**: 0
* **Key Strengths**: The architecture demonstrates exceptional clarity, modularity, and a strong alignment with NixOS best practices. The design is highly suitable for both manual and AI-driven development.
* **Sections Evaluated**: All sections were evaluated except for "Frontend Design" and "Accessibility," which are not applicable to this project.

#### Section Analysis
All applicable sections of the checklist have a **100% pass rate**. The design decisions are well-supported by the PRD and our interactive discussions, leaving no significant gaps or ambiguities.

#### Recommendations
There are no "must-fix" items. The architecture is considered complete and ready for the development phase.

#### AI Implementation Readiness
The readiness for AI agent implementation is **High**. The declarative nature of the project, combined with the clear Source Tree, explicit Coding Standards, and modular design, provides a structured environment where an AI agent can effectively and safely make modifications.
